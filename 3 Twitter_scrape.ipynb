{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Twitter scrapping with SNScrape\n",
        "[Author: Elias Buitrago Bolivar](https://github.com/ebuitrago?tab=repositories)\n",
        "\n",
        "Inspired in: https://www.youtube.com/watch?v=PUMMCLrVn8A\n",
        "\n",
        "Since Twitter API is no longer permit massive tweets downloads, there is space for alternative twitter data extraction strategies. Here is depicted a strategy to download until two hundred thousand tweets from a specific hashtag. Details and explanations for the laboratory will be given directly in class, therefore the material isn't autoexplained. And, please, give credits to the original author's idea and, if consider, also to me.\n",
        "\n",
        "_Updated: June 20th, 2023_"
      ],
      "metadata": {
        "id": "tmDNB6JxUeB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape #isn't working??"
      ],
      "metadata": {
        "id": "QwFhQTbpVIiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/JustAnotherArchivist/snscrape/issues/846#issuecomment-1542295576\n",
        "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git"
      ],
      "metadata": {
        "id": "oyRJL5r7W8Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4WQb9COJvRw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import snscrape.modules.twitter as sntwitter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraper = sntwitter.TwitterSearchScraper(\"#turismo\")"
      ],
      "metadata": {
        "id": "vxkFLOjqUwvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in scraper.get_items():\n",
        "  break"
      ],
      "metadata": {
        "id": "8VqezB5zVRlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet"
      ],
      "metadata": {
        "id": "SAiPjXOvVdQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option #1\n",
        "#Original author:\n",
        "#https://github.com/JustAnotherArchivist/snscrape/issues/846#issue-1677505887\n",
        "\n",
        "# Creating list to append tweet data to\n",
        "tweets_list1 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper('turismo since:2019-01-01 until:2022-12-31').get_items()):\n",
        "    # if i>maxTweets:\n",
        "    #     break\n",
        "\n",
        "    tweets_list1.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username])\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "\n",
        "        # Creating a dataframe from the tweets list above\n",
        "        tweet_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
        "        print(tweet_df1)\n",
        "\n",
        "        # Export dataframe into a csv\n",
        "        tweet_df1.to_csv(f'turismo-{(i+1)/100}.csv', sep=',', index=False)\n",
        "        tweets_list1 = []"
      ],
      "metadata": {
        "id": "sCEUuqqTXjSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option #2\n",
        "# https://www.youtube.com/watch?v=PUMMCLrVn8A\n",
        "scraper = sntwitter.TwitterSearchScraper(\"#turismo\")\n",
        "\n",
        "tweets = []\n",
        "n_tweets = 1_00\n",
        "\n",
        "for i, tweet in tqdm(enumerate(scraper.get_items()), total=n_tweets):\n",
        "  data = [\n",
        "      tweet.date,\n",
        "      tweet.id,\n",
        "      tweet.content,\n",
        "      tweet.user.username,\n",
        "      tweet.likeCount,\n",
        "      tweet.retweetCount,\n",
        "  ]\n",
        "  tweets.append(data)\n",
        "  if i > n_tweets:\n",
        "    break\n",
        "tweet_df = pd.DataFrame(\n",
        "    tweets, columns = [\"date\", \"id\", \"content\", \"username\", \"like_count\", \"retweet_count\"]\n",
        ")\n",
        "tweet_df.to_csv(\"python-tweets_test.csv\", index=False)"
      ],
      "metadata": {
        "id": "b1tNZohrZiXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uC6K2WTFXqTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}